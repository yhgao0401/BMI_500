{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ed8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f86265",
   "metadata": {},
   "source": [
    "# Mediapipe on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fb8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763759147.780436 4728761 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "W0000 00:00:1763759147.940998 4802425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1763759147.960704 4802425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "\n",
    "model_path = 'pose_landmarker_lite.task'\n",
    "video_path = \"Walking.mp4\"\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE  \n",
    ")\n",
    "\n",
    "landmarker = PoseLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_idx = 0\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"output_video.mp4\", fourcc, fps,\n",
    "                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert BGR â†’ RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to MediaPipe Image\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb_frame\n",
    "    )\n",
    "\n",
    "    # Call the landmarker\n",
    "    result = landmarker.detect(mp_image)\n",
    "\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        for i, landmark in enumerate(result.pose_landmarks[0]):\n",
    "            h, w, _ = frame.shape\n",
    "            cx = int(landmark.x * w)\n",
    "            cy = int(landmark.y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0,255,0), -1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c75071c8",
   "metadata": {},
   "source": [
    "# Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb77d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "def extract_features(file_data, kernel, win, feature):\n",
    "    data = np.load(file_data)\n",
    "    T = data.shape[0]\n",
    "\n",
    "    # Flatten the last two dimensions (33 keypoints * 2 coordinates)\n",
    "    data = data.reshape(T, 33 * 2)\n",
    "\n",
    "    #preprocess\n",
    "    for ch in range(data.shape[1]):\n",
    "        kps_seq_ch = data[:,ch]\n",
    "        # print(kps_seq_ch.shape)\n",
    "        kps_seq_ch=Series(kps_seq_ch).rolling(kernel,min_periods=1,center=True).mean().to_numpy()\n",
    "        data[:,ch]=kps_seq_ch\n",
    "\n",
    "    #sliding window parameters\n",
    "    win_len=int(30*win)\n",
    "    win_step=int(30*0.5)\n",
    "    sample_windows=[]\n",
    "    for start_time in range(0,data.shape[0], win_step):\n",
    "        end_time=start_time+win_len\n",
    "        if end_time>data.shape[0]:\n",
    "            end_time=data.shape[0]\n",
    "            start_time=end_time-win_len\n",
    "        frame=data[start_time:end_time]\n",
    "        assert frame.shape[0]==win_len, (start_time, end_time, data.shape[0])\n",
    "        sample_windows.append(frame)\n",
    "    sample_windows=np.array(sample_windows)\n",
    "    sample_windows.shape\n",
    "\n",
    "    #extract features from each frame\n",
    "    N, T, D =sample_windows.shape\n",
    "    feats=[]\n",
    "    for i in range(N):\n",
    "        frame=sample_windows[i]\n",
    "        feat=[]\n",
    "        for ch in range(D):\n",
    "            frame_ch=frame[:,ch]\n",
    "            if 'mean' in feature:\n",
    "                mean_ch=np.mean(frame_ch)\n",
    "                feat.append(mean_ch)\n",
    "            if 'std' in feature:\n",
    "                std_ch=np.std(frame_ch)\n",
    "                feat.append(std_ch)\n",
    "            if 'min' in feature:\n",
    "                min_ch=np.min(frame_ch)\n",
    "                feat.append(min_ch)\n",
    "            if 'max' in feature:\n",
    "                max_ch=np.max(frame_ch)\n",
    "                feat.append(max_ch)\n",
    "            if 'median' in feature:\n",
    "                med_ch=np.median(frame_ch)\n",
    "                feat.append(med_ch)\n",
    "        feats.append(feat)\n",
    "    feats=np.array(feats)\n",
    "\n",
    "    return np.array(feats)\n",
    "\n",
    "def get_label(file):\n",
    "    l=file.split('_')\n",
    "    label=int(l[0][1:])-1\n",
    "    subject_id=int(l[1][1:])\n",
    "    return label, subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b96c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(train_max, val_max, kernel, win, feature):\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_validation_list = []\n",
    "    y_validation_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    import os\n",
    "    all_video_files = os.listdir('pose/')\n",
    "\n",
    "    for file in all_video_files:\n",
    "        \n",
    "        label, subject_id=get_label(file)\n",
    "        \n",
    "        features = extract_features(f'pose/{file}',kernel, win, feature) \n",
    "        frame_labels = np.full(features.shape[0], label) \n",
    "\n",
    "        if subject_id <= train_max:\n",
    "            X_train_list.append(features)\n",
    "            y_train_list.append(frame_labels)\n",
    "        elif subject_id<=val_max:\n",
    "            X_validation_list.append(features)\n",
    "            y_validation_list.append(frame_labels)\n",
    "        else:\n",
    "            X_test_list.append(features)\n",
    "            y_test_list.append(frame_labels)\n",
    "\n",
    "\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_validation = np.concatenate(X_test_list, axis=0)\n",
    "    y_validation = np.concatenate(y_test_list, axis=0)\n",
    "    X_test = np.concatenate(X_test_list, axis=0)\n",
    "    y_test = np.concatenate(y_test_list, axis=0)\n",
    "    return X_train,y_train,X_validation, y_validation, X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c659cf7",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86fde302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhe/anaconda3/envs/bmi500/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config (50,) (alpha=1.0e-05): Val Accuracy = 0.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhe/anaconda3/envs/bmi500/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config (100, 10) (alpha=1.0e-05): Val Accuracy = 0.3149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhe/anaconda3/envs/bmi500/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config (100, 50, 20) (alpha=1.0e-04): Val Accuracy = 0.3927\n",
      "------------------------------\n",
      "Tuning complete. Best configuration: (50,) (alpha=1.0e-05)\n",
      "Best Validation Accuracy: 0.4611\n",
      "------------------------------\n",
      "FINAL EVALUATION ON TEST SET (Subjects 8-10):\n",
      "Test Accuracy: 0.4611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_clf = None\n",
    "best_params = {}\n",
    "\n",
    "# Example parameter combinations to check using the Validation set\n",
    "param_grid = [\n",
    "    {'hls': (50,), 'alpha': 1e-5},      \n",
    "    {'hls': (100, 10), 'alpha': 1e-5}, \n",
    "    {'hls': (100, 50, 20), 'alpha': 1e-4}, \n",
    "]\n",
    "\n",
    "kernel_size=5\n",
    "window_size=0.5\n",
    "train_max=5\n",
    "val_max=7\n",
    "feature=['min','max','median','mean','std']\n",
    "X_train,y_train,X_validation, y_validation, X_test,y_test=prepareData(train_max, val_max,kernel_size, window_size, feature)\n",
    "\n",
    "s=f'{\"=\"*20}Settings{\"=\"*20}\\n'\n",
    "s+=f'Kernel Size: {kernel_size}\\n'\n",
    "s+=f'Window Size: {window_size}\\n'\n",
    "s+=f'Train: Subject 1-{train_max}\\n'\n",
    "s+=f'Validation: Subject {train_max+1}-{val_max}\\n'\n",
    "s+=f'Test: Subject {val_max+1}-10\\n'\n",
    "s+=f'Feature: {\",\".join(feature)}\\n'\n",
    "s+=f'{\"=\"*40}\\n'\n",
    "\n",
    "for params in param_grid:\n",
    "    # 1. Create a Classifier with current parameters\n",
    "    clf = MLPClassifier(\n",
    "        solver='lbfgs',\n",
    "        hidden_layer_sizes=params['hls'],\n",
    "        alpha=params['alpha'],\n",
    "        random_state=42 \n",
    "    )\n",
    "    \n",
    "    # 2. Train the model \n",
    "    clf.fit(X_train, y_train) \n",
    "    \n",
    "    # 3. Predict and evaluate on val\n",
    "    y_val_pred = clf.predict(X_validation)\n",
    "    val_accuracy = accuracy_score(y_validation, y_val_pred)\n",
    "\n",
    "    s+=f\"Config {params['hls']} (alpha={params['alpha']:.1e}): Val Accuracy = {val_accuracy:.4f}\\n\"\n",
    "    print(f\"Config {params['hls']} (alpha={params['alpha']:.1e}): Val Accuracy = {val_accuracy:.4f}\")\n",
    "    \n",
    "    # 4. Best Model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_clf = clf\n",
    "        best_params = params\n",
    "\n",
    "s+=f'{\"-\" * 30}\\nTuning complete. Best configuration: {best_params[\"hls\"]} (alpha={best_params[\"alpha\"]:.1e})\\nBest Validation Accuracy: {best_val_accuracy:.4f}\\n'\n",
    "print(\"-\" * 30)\n",
    "print(f\"Tuning complete. Best configuration: {best_params['hls']} (alpha={best_params['alpha']:.1e})\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "if best_clf is not None:\n",
    "    y_test_pred = best_clf.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    s+=f'{\"-\" * 30}\\nFINAL EVALUATION ON TEST SET (Subjects 8-10):\\nTest Accuracy: {test_accuracy:.4f}'\n",
    "    print(\"-\" * 30)\n",
    "    print(\"FINAL EVALUATION ON TEST SET (Subjects 8-10):\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"Error: No model was trained successfully.\")\n",
    "\n",
    "with open(f\"k{kernel_size}_w{window_size}_train{train_max}_val{val_max}_{'_'.join(feature)}.txt\",'w') as f:\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64bbf0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2968487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 100 (max_d=10): Val Accuracy = 0.4740\n",
      "Config 50 (max_d=10): Val Accuracy = 0.4680\n",
      "Config 100 (max_d=15): Val Accuracy = 0.4939\n",
      "------------------------------\n",
      "Tuning complete. Best configuration: 100 (max_d=15)\n",
      "Best Validation Accuracy: 0.4939\n",
      "------------------------------\n",
      "FINAL EVALUATION ON TEST SET (Subjects 8-10):\n",
      "Test Accuracy: 0.4939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_clf = None\n",
    "best_params = {}\n",
    "\n",
    "# Example parameter combinations to check using the Validation set\n",
    "param_grid = [\n",
    "    {'n_trees': 100, 'max_d': 10},      \n",
    "    {'n_trees': 50, 'max_d': 10}, \n",
    "    {'n_trees': 100, 'max_d': 15}, \n",
    "]\n",
    "\n",
    "kernel_size=15\n",
    "window_size=1\n",
    "train_max=5\n",
    "val_max=7\n",
    "feature=['min','max','median','mean','std']\n",
    "\n",
    "X_train,y_train,X_validation, y_validation, X_test,y_test=prepareData(train_max, val_max,kernel_size, window_size, feature)\n",
    "\n",
    "s=f'{\"=\"*20}Settings{\"=\"*20}\\n'\n",
    "s+=f'Kernel Size: {kernel_size}\\n'\n",
    "s+=f'Window Size: {window_size}\\n'\n",
    "s+=f'Train: Subject 1-{train_max}\\n'\n",
    "s+=f'Validation: Subject {train_max+1}-{val_max}\\n'\n",
    "s+=f'Test: Subject {val_max+1}-10\\n'\n",
    "s+=f'Feature: {\",\".join(feature)}\\n'\n",
    "s+=f'{\"=\"*40}\\n'\n",
    "\n",
    "for params in param_grid:\n",
    "    # 1. Create a Classifier with current parameters\n",
    "    clf = RandomForestClassifier(n_estimators=params['n_trees'], max_depth=params['max_d'], random_state=42)\n",
    "    \n",
    "    # 2. Train the model \n",
    "    clf.fit(X_train, y_train) \n",
    "    \n",
    "    # 3. Predict and evaluate on val\n",
    "    y_val_pred = clf.predict(X_validation)\n",
    "    val_accuracy = accuracy_score(y_validation, y_val_pred)\n",
    "\n",
    "    s+=f\"Config {params['n_trees']} trees (max_d={params['max_d']}): Val Accuracy = {val_accuracy:.4f}\\n\"\n",
    "    print(f\"Config {params['n_trees']} (max_d={params['max_d']}): Val Accuracy = {val_accuracy:.4f}\")\n",
    "    \n",
    "    # 4. Best Model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_clf = clf\n",
    "        best_params = params\n",
    "\n",
    "s+=f'{\"-\" * 30}\\nTuning complete. Best configuration: {best_params[\"n_trees\"]} (max_d={best_params[\"max_d\"]})\\nBest Validation Accuracy: {best_val_accuracy:.4f}\\n'\n",
    "print(\"-\" * 30)\n",
    "print(f\"Tuning complete. Best configuration: {best_params['n_trees']} (max_d={best_params['max_d']})\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "if best_clf is not None:\n",
    "    y_test_pred = best_clf.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    s+=f'{\"-\" * 30}\\nFINAL EVALUATION ON TEST SET (Subjects 8-10):\\nTest Accuracy: {test_accuracy:.4f}'\n",
    "    print(\"-\" * 30)\n",
    "    print(\"FINAL EVALUATION ON TEST SET (Subjects 8-10):\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"Error: No model was trained successfully.\")\n",
    "\n",
    "with open(f\"RF_k{kernel_size}_w{window_size}_train{train_max}_val{val_max}_{'_'.join(feature)}.txt\",'w') as f:\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9e994",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmi500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
